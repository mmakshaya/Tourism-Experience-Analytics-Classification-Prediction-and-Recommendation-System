{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0766b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6251a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"tourism_sql.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d1a8e9",
   "metadata": {},
   "source": [
    "Content based"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874a6302",
   "metadata": {},
   "source": [
    "Based on attraction type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23bbfbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'] = df['Rating'].astype(str)\n",
    "tourism = df.copy() \n",
    "tourism = tourism.sample(n=3000, random_state=42).reset_index(drop=True)\n",
    "# STEP 2: Drop duplicate attractions based on content\n",
    "tourism = tourism.drop_duplicates(\n",
    "    subset=['Attraction', 'CityName', 'Country', 'AttractionType', 'Rating'],\n",
    "    keep='first'\n",
    ").reset_index(drop=True)\n",
    "# ✅ Create content from key features\n",
    "tourism['Attraction_recomendation'] = (\n",
    "    tourism['Attraction'] + ' ' +\n",
    "    tourism['AttractionType']+ ' ' +\n",
    "    tourism['CityName'] + ' ' +\n",
    "    tourism['Country'] + ' ' +\n",
    "    tourism['Rating'] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "935da31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Build TF-IDF matrix once (don't crash)\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(tourism['Attraction_recomendation'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b15173cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_attractions(attraction_name, city_name, df=tourism, cosine_sim=cosine_sim):\n",
    "    # Get the index matching both Attraction and City\n",
    "    idx = df[(df['Attraction'] == attraction_name) & (df['CityName'] == city_name)].index\n",
    "\n",
    "    if idx.empty:\n",
    "        return f\"Attraction '{attraction_name}' in '{city_name}' not found.\"\n",
    "\n",
    "    idx = idx[0]\n",
    "\n",
    "    # Get similarity scores\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort by similarity score (excluding itself)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "\n",
    "    # Get indices of top 5\n",
    "    top_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return recommended attractions\n",
    "    return df[['Attraction', 'CityName', 'Country', 'AttractionType', 'Rating']].iloc[top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31806652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>CityName</th>\n",
       "      <th>Country</th>\n",
       "      <th>AttractionType</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>Uluwatu Temple</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>Uluwatu Temple</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Tanah Lot Temple</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>Tanah Lot Temple</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>Tanah Lot Temple</td>\n",
       "      <td>London</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Attraction CityName         Country   AttractionType Rating\n",
       "1701    Uluwatu Temple   London  United Kingdom  Religious Sites      5\n",
       "659     Uluwatu Temple   Canada          Canada  Religious Sites      2\n",
       "586   Tanah Lot Temple   London  United Kingdom  Religious Sites      4\n",
       "2103  Tanah Lot Temple   London  United Kingdom  Religious Sites      1\n",
       "2120  Tanah Lot Temple   London  United Kingdom  Religious Sites      5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_attractions(\"Uluwatu Temple\", \"London\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35676778",
   "metadata": {},
   "source": [
    "Suggest attractions similar to those already visited by the user based on features like attraction type, location, and amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f7203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Attraction     CityName    Country   AttractionType Rating\n",
      "10495     Uluwatu Temple  Rockhampton  Australia  Religious Sites      4\n",
      "11448   Tanah Lot Temple  Rockhampton  Australia  Religious Sites      4\n",
      "11449  Kuta Beach - Bali  Rockhampton  Australia          Beaches      5\n",
      "11445     Nusa Dua Beach  Rockhampton  Australia          Beaches      4\n",
      "11446     Nusa Dua Beach  Rockhampton  Australia          Beaches      5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# STEP 1: Preprocessing\n",
    "tourism = df.copy()\n",
    "\n",
    "tourism.drop_duplicates(\n",
    "    subset=['Attraction', 'CityName', 'Country', 'AttractionType', 'Rating'],\n",
    "    inplace=True\n",
    ")\n",
    "tourism.reset_index(drop=True, inplace=True) \n",
    "\n",
    "# Combine features into a text field\n",
    "tourism['Attraction_recommendation'] = (\n",
    "    tourism['Attraction'].astype(str) + ' ' +\n",
    "    tourism['AttractionType'].astype(str) + ' ' +\n",
    "    tourism['CityName'].astype(str) + ' ' +\n",
    "    tourism['Country'].astype(str) + ' ' +\n",
    "    tourism['Rating'].astype(str)\n",
    ")\n",
    "\n",
    "# STEP 2: TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(tourism['Attraction_recommendation'])\n",
    "\n",
    "# STEP 3: User profile generator\n",
    "def build_user_profile(user_id, df=tourism, tfidf_matrix=tfidf_matrix):\n",
    "    visited = df[df['UserId'] == user_id]\n",
    "    if visited.empty:\n",
    "        return None, \"User has not visited any attractions.\"\n",
    "\n",
    "    # Get indices of user's visited attractions\n",
    "    user_indices = visited.index.tolist()\n",
    "\n",
    "    # Average TF-IDF vector for visited attractions\n",
    "    user_profile_vector = tfidf_matrix[user_indices].mean(axis=0)\n",
    "\n",
    "    return user_profile_vector, visited\n",
    "\n",
    "# STEP 4: Recommend attractions based on user profile\n",
    "def recommend_for_user(user_id, df=tourism, tfidf_matrix=tfidf_matrix, top_n=5):\n",
    "    user_profile_vector, visited = build_user_profile(user_id, df, tfidf_matrix)\n",
    "\n",
    "    if user_profile_vector is None:\n",
    "        return visited  # message\n",
    "\n",
    "    # Compute cosine similarity between user profile and all attractions\n",
    "    sim_scores = cosine_similarity(np.asarray(user_profile_vector), tfidf_matrix).flatten()\n",
    "\n",
    "\n",
    "    # Filter out attractions already visited\n",
    "    visited_indices = set(visited.index)\n",
    "    recommendations = [\n",
    "        (i, score) for i, score in enumerate(sim_scores) if i not in visited_indices\n",
    "    ]\n",
    "\n",
    "    # Sort and select top N\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    top_indices = [i[0] for i in recommendations]\n",
    "\n",
    "    return df[['Attraction', 'CityName', 'Country', 'AttractionType', 'Rating']].iloc[top_indices]\n",
    "\n",
    "# STEP 5: Example usage\n",
    "user_id = 694  # Replace with actual UserId\n",
    "print(recommend_for_user(user_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1230b169",
   "metadata": {},
   "source": [
    "collabrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdb0b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.6.1\n",
      "Uninstalling scikit-learn-1.6.1:\n",
      "  Successfully uninstalled scikit-learn-1.6.1\n",
      "Found existing installation: imbalanced-learn 0.13.0\n",
      "Uninstalling imbalanced-learn-0.13.0:\n",
      "  Successfully uninstalled imbalanced-learn-0.13.0\n",
      "Found existing installation: category_encoders 2.8.1\n",
      "Uninstalling category_encoders-2.8.1:\n",
      "  Successfully uninstalled category_encoders-2.8.1\n",
      "Collecting scikit-learn==1.3.2\n",
      "  Downloading scikit_learn-1.3.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting imbalanced-learn==0.11.0\n",
      "  Downloading imbalanced_learn-0.11.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting category_encoders==2.6.1\n",
      "  Downloading category_encoders-2.6.1-py2.py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.2) (3.5.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from category_encoders==2.6.1) (0.14.2)\n",
      "Requirement already satisfied: pandas>=1.0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from category_encoders==2.6.1) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from category_encoders==2.6.1) (0.5.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders==2.6.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders==2.6.1) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=1.0.5->category_encoders==2.6.1) (2023.3)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders==2.6.1) (1.16.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders==2.6.1) (24.1)\n",
      "Downloading scikit_learn-1.3.2-cp312-cp312-win_amd64.whl (9.1 MB)\n",
      "   ---------------------------------------- 0.0/9.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/9.1 MB 4.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.1/9.1 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 3.1/9.1 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.2/9.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.5/9.1 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.1 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/9.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.1/9.1 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "Downloading category_encoders-2.6.1-py2.py3-none-any.whl (81 kB)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn, category_encoders\n",
      "Successfully installed category_encoders-2.6.1 imbalanced-learn-0.11.0 scikit-learn-1.3.2\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58521823",
   "metadata": {},
   "source": [
    "\n",
    "1.Create a user-attraction matrix of ratings\n",
    "\n",
    "2.Compute user-user similarity\n",
    "\n",
    "3.Recommend attractions liked by similar users that the target user hasn't rated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866d4ed",
   "metadata": {},
   "source": [
    "Item based:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945e6c9",
   "metadata": {},
   "source": [
    "Item-Based Collaborative Filtering: Find attractions similar to those the target user has rated highly (based on other users’ ratings) and recommend them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1f259a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for user 70333\n",
      "- Waterbom Bali (Attraction ID: 841)\n",
      "- Kuta Beach - Bali (Attraction ID: 369)\n",
      "- Nusa Dua Beach (Attraction ID: 481)\n",
      "- Sanur Beach (Attraction ID: 650)\n",
      "- Seminyak Beach (Attraction ID: 673)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load your data\n",
    "# Replace with your file path or DataFrame as needed\n",
    "df=pd.read_csv(\"tourism_sql.csv\")\n",
    "# Step 2: Create User-Attraction Ratings Matrix\n",
    "ratings_matrix = df.pivot_table(index='UserId', columns='AttractionId', values='Rating')\n",
    "\n",
    "# Step 3: Fill NaN with 0 (or use mean imputation if preferred)\n",
    "ratings_filled = ratings_matrix.fillna(0)\n",
    "\n",
    "# Step 4: Calculate Item-Item Similarity (cosine similarity)\n",
    "item_similarity = cosine_similarity(ratings_filled.T)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, \n",
    "                                   index=ratings_filled.columns, \n",
    "                                   columns=ratings_filled.columns)\n",
    "\n",
    "# Step 5: Define a function to recommend similar attractions\n",
    "def recommend_attractions(user_id, top_n=5):\n",
    "    user_ratings = ratings_filled.loc[user_id]\n",
    "    unrated_items = user_ratings[user_ratings == 0]\n",
    "    \n",
    "    scores = {}\n",
    "    for item_id in unrated_items.index:\n",
    "        sim_items = item_similarity_df[item_id]\n",
    "        user_rated_items = user_ratings[user_ratings > 0]\n",
    "        weighted_sum = sum(sim_items[user_rated_items.index] * user_rated_items)\n",
    "        sim_sum = sum(sim_items[user_rated_items.index])\n",
    "        scores[item_id] = weighted_sum / sim_sum if sim_sum != 0 else 0\n",
    "\n",
    "    recommended = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    return [(item_id, df[df['AttractionId'] == item_id]['Attraction'].iloc[0]) for item_id, _ in recommended]\n",
    "\n",
    "# Example usage\n",
    "user_id = 70333  # Replace with an actual UserId from your dataset\n",
    "recommendations = recommend_attractions(user_id, top_n=5)\n",
    "\n",
    "# Print recommendations\n",
    "print(\"Top recommendations for user\", user_id)\n",
    "for item_id, attraction in recommendations:\n",
    "    print(f\"- {attraction} (Attraction ID: {item_id})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a8dc03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9200\n",
      "MAE:  0.7190\n",
      "Top-5 Recommendations:\n",
      "   AttractionId               Attraction  Predicted Rating\n",
      "0           748  Tegalalang Rice Terrace              4.16\n",
      "1           841            Waterbom Bali              4.16\n",
      "2           369        Kuta Beach - Bali              4.16\n",
      "3           650              Sanur Beach              4.16\n",
      "4           673           Seminyak Beach              4.16\n",
      "\n",
      "Evaluation for User 70333:\n",
      "Precision@5: 0.00\n",
      "Recall@5: 0.00\n",
      "MAP@5: 0.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# --- Load and prepare data ---\n",
    "# Ensure your DataFrame `df` contains: UserId, AttractionId, Rating, Attraction\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['UserId', 'AttractionId', 'Rating']], reader)\n",
    "\n",
    "# --- Train/test split ---\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# --- Train model ---\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# --- Predict on testset and calculate RMSE, MAE ---\n",
    "test_predictions = algo.test(testset)\n",
    "rmse = accuracy.rmse(test_predictions)\n",
    "mae = accuracy.mae(test_predictions)\n",
    "\n",
    "# --- Top-N Recommendations for a specific user ---\n",
    "user_id = str(70333)\n",
    "all_attractions = df['AttractionId'].unique()\n",
    "seen = df[df['UserId'] == int(user_id)]['AttractionId'].tolist()\n",
    "\n",
    "# Predict ratings for unseen attractions\n",
    "predictions = [algo.predict(user_id, str(i)) for i in all_attractions if i not in seen]\n",
    "top_n = sorted(predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommendations_df = pd.DataFrame({\n",
    "    \"AttractionId\": [int(pred.iid) for pred in top_n],\n",
    "    \"Attraction\": [df[df['AttractionId'] == int(pred.iid)]['Attraction'].iloc[0] for pred in top_n],\n",
    "    \"Predicted Rating\": [round(pred.est, 2) for pred in top_n]\n",
    "})\n",
    "\n",
    "print(\"Top-5 Recommendations:\")\n",
    "print(recommendations_df)\n",
    "\n",
    "# --- Evaluation: Precision@5, Recall@5, MAP@5 ---\n",
    "\n",
    "# Relevant items = attractions the user rated >= 4\n",
    "relevant = df[(df['UserId'] == int(user_id)) & (df['Rating'] >= 4)]['AttractionId'].tolist()\n",
    "recommended = [int(pred.iid) for pred in top_n]\n",
    "\n",
    "# Precision@5\n",
    "relevant_recommended = [aid for aid in recommended if aid in relevant]\n",
    "precision_at_5 = len(relevant_recommended) / len(recommended)\n",
    "\n",
    "# Recall@5\n",
    "recall_at_5 = len(relevant_recommended) / len(relevant) if relevant else 0\n",
    "\n",
    "# MAP@5\n",
    "def average_precision(recommended, relevant):\n",
    "    hits, sum_precisions = 0, 0\n",
    "    for i, aid in enumerate(recommended):\n",
    "        if aid in relevant:\n",
    "            hits += 1\n",
    "            sum_precisions += hits / (i + 1)\n",
    "    return sum_precisions / hits if hits else 0\n",
    "\n",
    "map_at_5 = average_precision(recommended, relevant)\n",
    "\n",
    "# --- Display evaluation ---\n",
    "print(f\"\\nEvaluation for User {user_id}:\")\n",
    "print(f\"Precision@5: {precision_at_5:.2f}\")\n",
    "print(f\"Recall@5: {recall_at_5:.2f}\")\n",
    "print(f\"MAP@5: {map_at_5:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fbe3c1",
   "metadata": {},
   "source": [
    "🔍 Your Results:\n",
    "🔢 Error Metrics (All Users):\n",
    "RMSE: 0.9200 — average error in predicted ratings is less than 1 unit (good).\n",
    "\n",
    "MAE: 0.7190 — average absolute error is ~0.72 stars (reasonable).\n",
    "\n",
    "✅ This means your SVD model is learning patterns reasonably well on rating prediction.\n",
    "\n",
    "📊 Recommendation Quality (User 70333):\n",
    "Precision@5: 0.00\n",
    "\n",
    "Recall@5: 0.00\n",
    "\n",
    "MAP@5: 0.00\n",
    "\n",
    "⚠️ This means none of the recommended items (Top-5) were among those the user rated ≥ 4, i.e., they were not relevant to this user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848fe52",
   "metadata": {},
   "source": [
    "\n",
    "User-Based Collaborative Filtering in Python using svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c231b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AttractionId               Attraction  Predicted Rating\n",
      "0           748  Tegalalang Rice Terrace              4.16\n",
      "1           841            Waterbom Bali              4.16\n",
      "2           369        Kuta Beach - Bali              4.16\n",
      "3           650              Sanur Beach              4.16\n",
      "4           673           Seminyak Beach              4.16\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Prepare the dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['UserId', 'AttractionId', 'Rating']], reader)\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict for a specific user\n",
    "user_id = str(70333)\n",
    "all_attractions = df['AttractionId'].unique()\n",
    "seen = df[df['UserId'] == int(user_id)]['AttractionId'].tolist()\n",
    "\n",
    "# Predict ratings for unseen attractions\n",
    "predictions = [algo.predict(user_id, str(i)) for i in all_attractions if i not in seen]\n",
    "top_n = sorted(predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "\n",
    "# Convert to DataFrame\n",
    "recommendations_df = pd.DataFrame({\n",
    "    \"AttractionId\": [int(pred.iid) for pred in top_n],\n",
    "    \"Attraction\": [df[df['AttractionId'] == int(pred.iid)]['Attraction'].iloc[0] for pred in top_n],\n",
    "    \"Predicted Rating\": [round(pred.est, 2) for pred in top_n]\n",
    "})\n",
    "\n",
    "# Display as table\n",
    "print(recommendations_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb28227",
   "metadata": {},
   "source": [
    "Item-Based Collaborative Filtering using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4744665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AttractionId                    Attraction  Similarity\n",
      "0          1220  Ramayana Ballet at Prambanan    0.243197\n",
      "1           947          Mount Semeru Volcano    0.139519\n",
      "2           749          Tegenungan Waterfall    0.115407\n",
      "3           737              Tanah Lot Temple    0.113244\n",
      "4           913                Goa Cina Beach    0.111410\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Prepare the dataset\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['UserId', 'AttractionId', 'Rating']], reader)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Step 1: Build mapping of internal IDs to attraction IDs\n",
    "raw_to_inner = trainset.to_inner_iid\n",
    "inner_to_raw = trainset.to_raw_iid\n",
    "\n",
    "# Step 2: Extract item (attraction) latent vectors\n",
    "item_factors = np.array([algo.qi[raw_to_inner(i)] for i in df['AttractionId'].unique() if raw_to_inner(i) < len(algo.qi)])\n",
    "item_ids = [i for i in df['AttractionId'].unique() if raw_to_inner(i) < len(algo.qi)]\n",
    "\n",
    "# Step 3: Compute cosine similarity between items\n",
    "item_sim = cosine_similarity(item_factors)\n",
    "\n",
    "# Step 4: Create a DataFrame for similarity\n",
    "sim_df = pd.DataFrame(item_sim, index=item_ids, columns=item_ids)\n",
    "\n",
    "# Step 5: Define function to get top N similar attractions\n",
    "def get_similar_attractions(attraction_id, top_n=5):\n",
    "    if attraction_id not in sim_df.index:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    similar_scores = sim_df[attraction_id].sort_values(ascending=False)[1:top_n+1]  # Skip self (first row)\n",
    "    result = pd.DataFrame({\n",
    "        \"AttractionId\": similar_scores.index,\n",
    "        \"Attraction\": [df[df['AttractionId'] == i]['Attraction'].iloc[0] for i in similar_scores.index],\n",
    "        \"Similarity\": similar_scores.values\n",
    "    })\n",
    "    return result\n",
    "\n",
    "# Example: get similar attractions to 'Uluwatu Temple' (ID = 824)\n",
    "similar_attractions_df = get_similar_attractions(824)\n",
    "print(similar_attractions_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaa6401",
   "metadata": {},
   "source": [
    "Hybrid Recommendation System (CF + CBF) using svd\n",
    "\n",
    "Creating a hybrid recommendation system combines the strengths of both:\n",
    "\n",
    "Collaborative Filtering (CF): Learns from user-item interactions.\n",
    "\n",
    "Content-Based Filtering (CBF): Uses item features to find similar content.\n",
    "\n",
    "SVD-based Collaborative Filtering: to predict how much a user would like an item.\n",
    "\n",
    "TF-IDF-based Content Similarity: to adjust recommendations with item similarity.\n",
    "\n",
    "🔧 Hybrid Strategy For a given user + attraction, we:\n",
    "\n",
    "Use SVD to predict rating for unseen attractions.\n",
    "\n",
    "Use content similarity to filter those that are most similar to what the user has rated highly.\n",
    "\n",
    "Combine both scores (weighted average).\n",
    "\n",
    "⚖️ Parameter alpha alpha = 1.0: pure collaborative\n",
    "\n",
    "alpha = 0.0: pure content-based\n",
    "\n",
    "alpha = 0.5: balanced hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64485580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from surprise import SVD, Dataset, Reader\n",
    "\n",
    "# Step 1: Prepare content-based data\n",
    "df['Rating'] = df['Rating'].astype(str)\n",
    "tourism = df.sample(n=3000, random_state=42).drop_duplicates(\n",
    "    subset=['Attraction', 'CityName', 'Country', 'AttractionType', 'Rating']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "tourism['Attraction_recommendation'] = (\n",
    "    tourism['Attraction'] + ' ' +\n",
    "    tourism['AttractionType'] + ' ' +\n",
    "    tourism['CityName'] + ' ' +\n",
    "    tourism['Country'] + ' ' +\n",
    "    tourism['Rating']\n",
    ")\n",
    "\n",
    "# Step 2: Compute TF-IDF content similarity matrix\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(tourism['Attraction_recommendation'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Step 3: Collaborative Filtering with SVD\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[['UserId', 'AttractionId', 'Rating']].astype(float), reader)\n",
    "trainset = data.build_full_trainset()\n",
    "svd_model = SVD()\n",
    "svd_model.fit(trainset)\n",
    "\n",
    "# Step 4: Hybrid Recommendation Function\n",
    "def hybrid_recommend(user_id, liked_attraction, city_name, top_n=5, alpha=0.5):\n",
    "    # Find index of liked attraction\n",
    "    idx = tourism[(tourism['Attraction'] == liked_attraction) & (tourism['CityName'] == city_name)].index\n",
    "    if idx.empty:\n",
    "        return f\"Attraction '{liked_attraction}' in '{city_name}' not found.\"\n",
    "\n",
    "    idx = idx[0]\n",
    "\n",
    "    # Step A: Get similar attractions based on content\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:50]  # Take top 50 similar for performance\n",
    "    candidate_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Step B: Predict ratings with collaborative filtering\n",
    "    hybrid_scores = []\n",
    "    for i in candidate_indices:\n",
    "        attraction_id = tourism.loc[i, 'AttractionId']\n",
    "        pred = svd_model.predict(str(user_id), str(attraction_id)).est\n",
    "        content_score = cosine_sim[idx][i]\n",
    "        hybrid_score = alpha * pred + (1 - alpha) * content_score #2.85\n",
    "        hybrid_scores.append((i, hybrid_score))\n",
    "\n",
    "    # Step C: Sort by hybrid score\n",
    "    hybrid_scores = sorted(hybrid_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Step D: Return recommended attractions\n",
    "    top_indices = [i[0] for i in hybrid_scores]\n",
    "    return tourism[['Attraction', 'CityName', 'Country', 'AttractionType', 'Rating']].iloc[top_indices].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93ca67dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attraction</th>\n",
       "      <th>CityName</th>\n",
       "      <th>Country</th>\n",
       "      <th>AttractionType</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uluwatu Temple</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uluwatu Temple</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>United States</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Uluwatu Temple</td>\n",
       "      <td>Houston</td>\n",
       "      <td>United States</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uluwatu Temple</td>\n",
       "      <td>Austin</td>\n",
       "      <td>United States</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tanah Lot Temple</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>Religious Sites</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Attraction       CityName        Country   AttractionType Rating\n",
       "0    Uluwatu Temple  United States  United States  Religious Sites      5\n",
       "1    Uluwatu Temple      Amsterdam  United States  Religious Sites      5\n",
       "2    Uluwatu Temple        Houston  United States  Religious Sites      3\n",
       "3    Uluwatu Temple         Austin  United States  Religious Sites      4\n",
       "4  Tanah Lot Temple  United States  United States  Religious Sites      5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_recommend(user_id=70333, liked_attraction=\"Uluwatu Temple\", city_name=\"Saratoga\", top_n=5, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf4be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9918eb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
